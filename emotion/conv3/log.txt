I0628 16:43:12.100162 23581 caffe.cpp:204] Using GPUs 0
I0628 16:43:15.190413 23581 caffe.cpp:209] GPU 0: GeForce GTX 1080 Ti
I0628 16:43:15.678326 23581 solver.cpp:45] Initializing solver from parameters: 
test_iter: 100
test_interval: 100
base_lr: 1e-05
display: 100
max_iter: 10000
lr_policy: "fixed"
momentum: 0.9
snapshot: 2000
snapshot_prefix: "./snaps/simpleconv3_"
solver_mode: GPU
device_id: 0
net: "./train.prototxt"
train_state {
  level: 0
  stage: ""
}
type: "Adam"
I0628 16:43:15.678632 23581 solver.cpp:102] Creating training net from net file: ./train.prototxt
I0628 16:43:15.679145 23581 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./train.prototxt
I0628 16:43:15.679169 23581 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0628 16:43:15.679289 23581 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0628 16:43:15.679704 23581 net.cpp:53] Initializing net from parameters: 
name: "simpleconv3"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 48
    mean_value: 104.008
    mean_value: 116.669
    mean_value: 122.675
  }
  image_data_param {
    source: "train.txt"
    batch_size: 96
    shuffle: true
    root_folder: "../images_128/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "conv3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "acc"
}
I0628 16:43:15.679992 23581 layer_factory.hpp:77] Creating layer data
I0628 16:43:15.680063 23581 net.cpp:86] Creating Layer data
I0628 16:43:15.680085 23581 net.cpp:382] data -> data
I0628 16:43:15.680131 23581 net.cpp:382] data -> label
I0628 16:43:15.680677 23581 image_data_layer.cpp:38] Opening file train.txt
I0628 16:43:15.685252 23581 image_data_layer.cpp:53] Shuffling data
I0628 16:43:15.685750 23581 image_data_layer.cpp:63] A total of 13596 images.
I0628 16:43:15.688738 23581 image_data_layer.cpp:90] output data size: 96,3,48,48
I0628 16:43:15.706277 23581 net.cpp:124] Setting up data
I0628 16:43:15.706315 23581 net.cpp:131] Top shape: 96 3 48 48 (663552)
I0628 16:43:15.706326 23581 net.cpp:131] Top shape: 96 (96)
I0628 16:43:15.706333 23581 net.cpp:139] Memory required for data: 2654592
I0628 16:43:15.706346 23581 layer_factory.hpp:77] Creating layer label_data_1_split
I0628 16:43:15.706364 23581 net.cpp:86] Creating Layer label_data_1_split
I0628 16:43:15.706379 23581 net.cpp:408] label_data_1_split <- label
I0628 16:43:15.706401 23581 net.cpp:382] label_data_1_split -> label_data_1_split_0
I0628 16:43:15.706423 23581 net.cpp:382] label_data_1_split -> label_data_1_split_1
I0628 16:43:15.706758 23581 net.cpp:124] Setting up label_data_1_split
I0628 16:43:15.706825 23581 net.cpp:131] Top shape: 96 (96)
I0628 16:43:15.706835 23581 net.cpp:131] Top shape: 96 (96)
I0628 16:43:15.706849 23581 net.cpp:139] Memory required for data: 2655360
I0628 16:43:15.706862 23581 layer_factory.hpp:77] Creating layer conv1
I0628 16:43:15.706921 23581 net.cpp:86] Creating Layer conv1
I0628 16:43:15.706938 23581 net.cpp:408] conv1 <- data
I0628 16:43:15.706956 23581 net.cpp:382] conv1 -> conv1
I0628 16:43:16.611858 23581 net.cpp:124] Setting up conv1
I0628 16:43:16.611915 23581 net.cpp:131] Top shape: 96 12 24 24 (663552)
I0628 16:43:16.611922 23581 net.cpp:139] Memory required for data: 5309568
I0628 16:43:16.611970 23581 layer_factory.hpp:77] Creating layer conv1/bn
I0628 16:43:16.612009 23581 net.cpp:86] Creating Layer conv1/bn
I0628 16:43:16.612025 23581 net.cpp:408] conv1/bn <- conv1
I0628 16:43:16.612033 23581 net.cpp:369] conv1/bn -> conv1 (in-place)
I0628 16:43:16.612265 23581 net.cpp:124] Setting up conv1/bn
I0628 16:43:16.612277 23581 net.cpp:131] Top shape: 96 12 24 24 (663552)
I0628 16:43:16.612282 23581 net.cpp:139] Memory required for data: 7963776
I0628 16:43:16.612301 23581 layer_factory.hpp:77] Creating layer conv1/scale
I0628 16:43:16.612329 23581 net.cpp:86] Creating Layer conv1/scale
I0628 16:43:16.612334 23581 net.cpp:408] conv1/scale <- conv1
I0628 16:43:16.612341 23581 net.cpp:369] conv1/scale -> conv1 (in-place)
I0628 16:43:16.612417 23581 layer_factory.hpp:77] Creating layer conv1/scale
I0628 16:43:16.612553 23581 net.cpp:124] Setting up conv1/scale
I0628 16:43:16.612565 23581 net.cpp:131] Top shape: 96 12 24 24 (663552)
I0628 16:43:16.612570 23581 net.cpp:139] Memory required for data: 10617984
I0628 16:43:16.612577 23581 layer_factory.hpp:77] Creating layer relu1
I0628 16:43:16.612651 23581 net.cpp:86] Creating Layer relu1
I0628 16:43:16.612663 23581 net.cpp:408] relu1 <- conv1
I0628 16:43:16.612669 23581 net.cpp:369] relu1 -> conv1 (in-place)
I0628 16:43:16.613137 23581 net.cpp:124] Setting up relu1
I0628 16:43:16.613152 23581 net.cpp:131] Top shape: 96 12 24 24 (663552)
I0628 16:43:16.613157 23581 net.cpp:139] Memory required for data: 13272192
I0628 16:43:16.613160 23581 layer_factory.hpp:77] Creating layer conv2
I0628 16:43:16.613174 23581 net.cpp:86] Creating Layer conv2
I0628 16:43:16.613178 23581 net.cpp:408] conv2 <- conv1
I0628 16:43:16.613186 23581 net.cpp:382] conv2 -> conv2
I0628 16:43:16.616803 23581 net.cpp:124] Setting up conv2
I0628 16:43:16.616819 23581 net.cpp:131] Top shape: 96 24 12 12 (331776)
I0628 16:43:16.616824 23581 net.cpp:139] Memory required for data: 14599296
I0628 16:43:16.616850 23581 layer_factory.hpp:77] Creating layer conv2/bn
I0628 16:43:16.616860 23581 net.cpp:86] Creating Layer conv2/bn
I0628 16:43:16.616865 23581 net.cpp:408] conv2/bn <- conv2
I0628 16:43:16.616873 23581 net.cpp:369] conv2/bn -> conv2 (in-place)
I0628 16:43:16.617060 23581 net.cpp:124] Setting up conv2/bn
I0628 16:43:16.617075 23581 net.cpp:131] Top shape: 96 24 12 12 (331776)
I0628 16:43:16.617079 23581 net.cpp:139] Memory required for data: 15926400
I0628 16:43:16.617089 23581 layer_factory.hpp:77] Creating layer conv2/scale
I0628 16:43:16.617096 23581 net.cpp:86] Creating Layer conv2/scale
I0628 16:43:16.617101 23581 net.cpp:408] conv2/scale <- conv2
I0628 16:43:16.617107 23581 net.cpp:369] conv2/scale -> conv2 (in-place)
I0628 16:43:16.617163 23581 layer_factory.hpp:77] Creating layer conv2/scale
I0628 16:43:16.617318 23581 net.cpp:124] Setting up conv2/scale
I0628 16:43:16.617328 23581 net.cpp:131] Top shape: 96 24 12 12 (331776)
I0628 16:43:16.617332 23581 net.cpp:139] Memory required for data: 17253504
I0628 16:43:16.617341 23581 layer_factory.hpp:77] Creating layer relu2
I0628 16:43:16.617347 23581 net.cpp:86] Creating Layer relu2
I0628 16:43:16.617350 23581 net.cpp:408] relu2 <- conv2
I0628 16:43:16.617355 23581 net.cpp:369] relu2 -> conv2 (in-place)
I0628 16:43:16.617919 23581 net.cpp:124] Setting up relu2
I0628 16:43:16.617931 23581 net.cpp:131] Top shape: 96 24 12 12 (331776)
I0628 16:43:16.617935 23581 net.cpp:139] Memory required for data: 18580608
I0628 16:43:16.617947 23581 layer_factory.hpp:77] Creating layer conv3
I0628 16:43:16.617961 23581 net.cpp:86] Creating Layer conv3
I0628 16:43:16.617977 23581 net.cpp:408] conv3 <- conv2
I0628 16:43:16.617987 23581 net.cpp:382] conv3 -> conv3
I0628 16:43:16.621709 23581 net.cpp:124] Setting up conv3
I0628 16:43:16.621737 23581 net.cpp:131] Top shape: 96 48 6 6 (165888)
I0628 16:43:16.621742 23581 net.cpp:139] Memory required for data: 19244160
I0628 16:43:16.621750 23581 layer_factory.hpp:77] Creating layer conv3/bn
I0628 16:43:16.621758 23581 net.cpp:86] Creating Layer conv3/bn
I0628 16:43:16.621762 23581 net.cpp:408] conv3/bn <- conv3
I0628 16:43:16.621773 23581 net.cpp:369] conv3/bn -> conv3 (in-place)
I0628 16:43:16.622061 23581 net.cpp:124] Setting up conv3/bn
I0628 16:43:16.622071 23581 net.cpp:131] Top shape: 96 48 6 6 (165888)
I0628 16:43:16.622076 23581 net.cpp:139] Memory required for data: 19907712
I0628 16:43:16.622090 23581 layer_factory.hpp:77] Creating layer conv3/scale
I0628 16:43:16.622098 23581 net.cpp:86] Creating Layer conv3/scale
I0628 16:43:16.622117 23581 net.cpp:408] conv3/scale <- conv3
I0628 16:43:16.622123 23581 net.cpp:369] conv3/scale -> conv3 (in-place)
I0628 16:43:16.622189 23581 layer_factory.hpp:77] Creating layer conv3/scale
I0628 16:43:16.622362 23581 net.cpp:124] Setting up conv3/scale
I0628 16:43:16.622385 23581 net.cpp:131] Top shape: 96 48 6 6 (165888)
I0628 16:43:16.622390 23581 net.cpp:139] Memory required for data: 20571264
I0628 16:43:16.622397 23581 layer_factory.hpp:77] Creating layer relu3
I0628 16:43:16.622403 23581 net.cpp:86] Creating Layer relu3
I0628 16:43:16.622407 23581 net.cpp:408] relu3 <- conv3
I0628 16:43:16.622413 23581 net.cpp:369] relu3 -> conv3 (in-place)
I0628 16:43:16.623519 23581 net.cpp:124] Setting up relu3
I0628 16:43:16.623554 23581 net.cpp:131] Top shape: 96 48 6 6 (165888)
I0628 16:43:16.623560 23581 net.cpp:139] Memory required for data: 21234816
I0628 16:43:16.623575 23581 layer_factory.hpp:77] Creating layer ip1
I0628 16:43:16.623594 23581 net.cpp:86] Creating Layer ip1
I0628 16:43:16.623600 23581 net.cpp:408] ip1 <- conv3
I0628 16:43:16.623625 23581 net.cpp:382] ip1 -> ip1
I0628 16:43:16.626546 23581 net.cpp:124] Setting up ip1
I0628 16:43:16.626561 23581 net.cpp:131] Top shape: 96 128 (12288)
I0628 16:43:16.626565 23581 net.cpp:139] Memory required for data: 21283968
I0628 16:43:16.626574 23581 layer_factory.hpp:77] Creating layer ip2
I0628 16:43:16.626585 23581 net.cpp:86] Creating Layer ip2
I0628 16:43:16.626590 23581 net.cpp:408] ip2 <- ip1
I0628 16:43:16.626600 23581 net.cpp:382] ip2 -> ip2
I0628 16:43:16.626760 23581 net.cpp:124] Setting up ip2
I0628 16:43:16.626770 23581 net.cpp:131] Top shape: 96 4 (384)
I0628 16:43:16.626775 23581 net.cpp:139] Memory required for data: 21285504
I0628 16:43:16.626781 23581 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0628 16:43:16.626794 23581 net.cpp:86] Creating Layer ip2_ip2_0_split
I0628 16:43:16.626801 23581 net.cpp:408] ip2_ip2_0_split <- ip2
I0628 16:43:16.626809 23581 net.cpp:382] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0628 16:43:16.626819 23581 net.cpp:382] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0628 16:43:16.626881 23581 net.cpp:124] Setting up ip2_ip2_0_split
I0628 16:43:16.626893 23581 net.cpp:131] Top shape: 96 4 (384)
I0628 16:43:16.626899 23581 net.cpp:131] Top shape: 96 4 (384)
I0628 16:43:16.626902 23581 net.cpp:139] Memory required for data: 21288576
I0628 16:43:16.626906 23581 layer_factory.hpp:77] Creating layer loss
I0628 16:43:16.626922 23581 net.cpp:86] Creating Layer loss
I0628 16:43:16.626930 23581 net.cpp:408] loss <- ip2_ip2_0_split_0
I0628 16:43:16.626936 23581 net.cpp:408] loss <- label_data_1_split_0
I0628 16:43:16.626943 23581 net.cpp:382] loss -> loss
I0628 16:43:16.626956 23581 layer_factory.hpp:77] Creating layer loss
I0628 16:43:16.627758 23581 net.cpp:124] Setting up loss
I0628 16:43:16.627773 23581 net.cpp:131] Top shape: (1)
I0628 16:43:16.627776 23581 net.cpp:134]     with loss weight 1
I0628 16:43:16.627810 23581 net.cpp:139] Memory required for data: 21288580
I0628 16:43:16.627815 23581 layer_factory.hpp:77] Creating layer acc
I0628 16:43:16.627823 23581 net.cpp:86] Creating Layer acc
I0628 16:43:16.627830 23581 net.cpp:408] acc <- ip2_ip2_0_split_1
I0628 16:43:16.627836 23581 net.cpp:408] acc <- label_data_1_split_1
I0628 16:43:16.627843 23581 net.cpp:382] acc -> acc
I0628 16:43:16.627872 23581 net.cpp:124] Setting up acc
I0628 16:43:16.627880 23581 net.cpp:131] Top shape: (1)
I0628 16:43:16.627884 23581 net.cpp:139] Memory required for data: 21288584
I0628 16:43:16.627889 23581 net.cpp:202] acc does not need backward computation.
I0628 16:43:16.627894 23581 net.cpp:200] loss needs backward computation.
I0628 16:43:16.627899 23581 net.cpp:200] ip2_ip2_0_split needs backward computation.
I0628 16:43:16.627903 23581 net.cpp:200] ip2 needs backward computation.
I0628 16:43:16.627908 23581 net.cpp:200] ip1 needs backward computation.
I0628 16:43:16.627912 23581 net.cpp:200] relu3 needs backward computation.
I0628 16:43:16.627916 23581 net.cpp:200] conv3/scale needs backward computation.
I0628 16:43:16.627919 23581 net.cpp:200] conv3/bn needs backward computation.
I0628 16:43:16.627935 23581 net.cpp:200] conv3 needs backward computation.
I0628 16:43:16.627940 23581 net.cpp:200] relu2 needs backward computation.
I0628 16:43:16.627944 23581 net.cpp:200] conv2/scale needs backward computation.
I0628 16:43:16.627948 23581 net.cpp:200] conv2/bn needs backward computation.
I0628 16:43:16.627952 23581 net.cpp:200] conv2 needs backward computation.
I0628 16:43:16.627956 23581 net.cpp:200] relu1 needs backward computation.
I0628 16:43:16.627960 23581 net.cpp:200] conv1/scale needs backward computation.
I0628 16:43:16.627964 23581 net.cpp:200] conv1/bn needs backward computation.
I0628 16:43:16.627967 23581 net.cpp:200] conv1 needs backward computation.
I0628 16:43:16.627995 23581 net.cpp:202] label_data_1_split does not need backward computation.
I0628 16:43:16.628010 23581 net.cpp:202] data does not need backward computation.
I0628 16:43:16.628016 23581 net.cpp:244] This network produces output acc
I0628 16:43:16.628021 23581 net.cpp:244] This network produces output loss
I0628 16:43:16.628038 23581 net.cpp:257] Network initialization done.
I0628 16:43:16.628638 23581 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./train.prototxt
I0628 16:43:16.628648 23581 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0628 16:43:16.628657 23581 solver.cpp:190] Creating test net (#0) specified by net file: ./train.prototxt
I0628 16:43:16.628693 23581 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0628 16:43:16.628901 23581 net.cpp:53] Initializing net from parameters: 
name: "simpleconv3"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 48
    mean_value: 104.008
    mean_value: 116.669
    mean_value: 122.675
  }
  image_data_param {
    source: "val.txt"
    batch_size: 16
    shuffle: false
    root_folder: "../images_128/"
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 12
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv2/scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv3/scale"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    filler {
      value: 1
    }
    bias_term: true
    bias_filler {
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "conv3"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "acc"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "acc"
}
I0628 16:43:16.629005 23581 layer_factory.hpp:77] Creating layer data
I0628 16:43:16.629024 23581 net.cpp:86] Creating Layer data
I0628 16:43:16.629032 23581 net.cpp:382] data -> data
I0628 16:43:16.629042 23581 net.cpp:382] data -> label
I0628 16:43:16.629055 23581 image_data_layer.cpp:38] Opening file val.txt
I0628 16:43:16.629377 23581 image_data_layer.cpp:63] A total of 1510 images.
I0628 16:43:16.629838 23581 image_data_layer.cpp:90] output data size: 16,3,48,48
I0628 16:43:16.631882 23581 net.cpp:124] Setting up data
I0628 16:43:16.631911 23581 net.cpp:131] Top shape: 16 3 48 48 (110592)
I0628 16:43:16.631917 23581 net.cpp:131] Top shape: 16 (16)
I0628 16:43:16.631922 23581 net.cpp:139] Memory required for data: 442432
I0628 16:43:16.631927 23581 layer_factory.hpp:77] Creating layer label_data_1_split
I0628 16:43:16.631934 23581 net.cpp:86] Creating Layer label_data_1_split
I0628 16:43:16.631939 23581 net.cpp:408] label_data_1_split <- label
I0628 16:43:16.631947 23581 net.cpp:382] label_data_1_split -> label_data_1_split_0
I0628 16:43:16.631956 23581 net.cpp:382] label_data_1_split -> label_data_1_split_1
I0628 16:43:16.632009 23581 net.cpp:124] Setting up label_data_1_split
I0628 16:43:16.632025 23581 net.cpp:131] Top shape: 16 (16)
I0628 16:43:16.632030 23581 net.cpp:131] Top shape: 16 (16)
I0628 16:43:16.632035 23581 net.cpp:139] Memory required for data: 442560
I0628 16:43:16.632040 23581 layer_factory.hpp:77] Creating layer conv1
I0628 16:43:16.632053 23581 net.cpp:86] Creating Layer conv1
I0628 16:43:16.632059 23581 net.cpp:408] conv1 <- data
I0628 16:43:16.632067 23581 net.cpp:382] conv1 -> conv1
I0628 16:43:16.639390 23581 net.cpp:124] Setting up conv1
I0628 16:43:16.639426 23581 net.cpp:131] Top shape: 16 12 24 24 (110592)
I0628 16:43:16.639436 23581 net.cpp:139] Memory required for data: 884928
I0628 16:43:16.639461 23581 layer_factory.hpp:77] Creating layer conv1/bn
I0628 16:43:16.639483 23581 net.cpp:86] Creating Layer conv1/bn
I0628 16:43:16.639494 23581 net.cpp:408] conv1/bn <- conv1
I0628 16:43:16.639510 23581 net.cpp:369] conv1/bn -> conv1 (in-place)
I0628 16:43:16.639966 23581 net.cpp:124] Setting up conv1/bn
I0628 16:43:16.639988 23581 net.cpp:131] Top shape: 16 12 24 24 (110592)
I0628 16:43:16.639997 23581 net.cpp:139] Memory required for data: 1327296
I0628 16:43:16.640018 23581 layer_factory.hpp:77] Creating layer conv1/scale
I0628 16:43:16.640038 23581 net.cpp:86] Creating Layer conv1/scale
I0628 16:43:16.640048 23581 net.cpp:408] conv1/scale <- conv1
I0628 16:43:16.640059 23581 net.cpp:369] conv1/scale -> conv1 (in-place)
I0628 16:43:16.640161 23581 layer_factory.hpp:77] Creating layer conv1/scale
I0628 16:43:16.640434 23581 net.cpp:124] Setting up conv1/scale
I0628 16:43:16.640453 23581 net.cpp:131] Top shape: 16 12 24 24 (110592)
I0628 16:43:16.640461 23581 net.cpp:139] Memory required for data: 1769664
I0628 16:43:16.640475 23581 layer_factory.hpp:77] Creating layer relu1
I0628 16:43:16.640496 23581 net.cpp:86] Creating Layer relu1
I0628 16:43:16.640548 23581 net.cpp:408] relu1 <- conv1
I0628 16:43:16.640568 23581 net.cpp:369] relu1 -> conv1 (in-place)
I0628 16:43:16.641669 23581 net.cpp:124] Setting up relu1
I0628 16:43:16.641692 23581 net.cpp:131] Top shape: 16 12 24 24 (110592)
I0628 16:43:16.641700 23581 net.cpp:139] Memory required for data: 2212032
I0628 16:43:16.641708 23581 layer_factory.hpp:77] Creating layer conv2
I0628 16:43:16.641734 23581 net.cpp:86] Creating Layer conv2
I0628 16:43:16.641743 23581 net.cpp:408] conv2 <- conv1
I0628 16:43:16.641762 23581 net.cpp:382] conv2 -> conv2
I0628 16:43:16.646670 23581 net.cpp:124] Setting up conv2
I0628 16:43:16.646697 23581 net.cpp:131] Top shape: 16 24 12 12 (55296)
I0628 16:43:16.646706 23581 net.cpp:139] Memory required for data: 2433216
I0628 16:43:16.646733 23581 layer_factory.hpp:77] Creating layer conv2/bn
I0628 16:43:16.646751 23581 net.cpp:86] Creating Layer conv2/bn
I0628 16:43:16.646767 23581 net.cpp:408] conv2/bn <- conv2
I0628 16:43:16.646788 23581 net.cpp:369] conv2/bn -> conv2 (in-place)
I0628 16:43:16.647204 23581 net.cpp:124] Setting up conv2/bn
I0628 16:43:16.647224 23581 net.cpp:131] Top shape: 16 24 12 12 (55296)
I0628 16:43:16.647233 23581 net.cpp:139] Memory required for data: 2654400
I0628 16:43:16.647248 23581 layer_factory.hpp:77] Creating layer conv2/scale
I0628 16:43:16.647265 23581 net.cpp:86] Creating Layer conv2/scale
I0628 16:43:16.647274 23581 net.cpp:408] conv2/scale <- conv2
I0628 16:43:16.647289 23581 net.cpp:369] conv2/scale -> conv2 (in-place)
I0628 16:43:16.647379 23581 layer_factory.hpp:77] Creating layer conv2/scale
I0628 16:43:16.647665 23581 net.cpp:124] Setting up conv2/scale
I0628 16:43:16.647682 23581 net.cpp:131] Top shape: 16 24 12 12 (55296)
I0628 16:43:16.647689 23581 net.cpp:139] Memory required for data: 2875584
I0628 16:43:16.647701 23581 layer_factory.hpp:77] Creating layer relu2
I0628 16:43:16.647711 23581 net.cpp:86] Creating Layer relu2
I0628 16:43:16.647718 23581 net.cpp:408] relu2 <- conv2
I0628 16:43:16.647730 23581 net.cpp:369] relu2 -> conv2 (in-place)
I0628 16:43:16.649194 23581 net.cpp:124] Setting up relu2
I0628 16:43:16.649215 23581 net.cpp:131] Top shape: 16 24 12 12 (55296)
I0628 16:43:16.649222 23581 net.cpp:139] Memory required for data: 3096768
I0628 16:43:16.649230 23581 layer_factory.hpp:77] Creating layer conv3
I0628 16:43:16.649250 23581 net.cpp:86] Creating Layer conv3
I0628 16:43:16.649258 23581 net.cpp:408] conv3 <- conv2
I0628 16:43:16.649272 23581 net.cpp:382] conv3 -> conv3
I0628 16:43:16.653550 23581 net.cpp:124] Setting up conv3
I0628 16:43:16.653574 23581 net.cpp:131] Top shape: 16 48 6 6 (27648)
I0628 16:43:16.653581 23581 net.cpp:139] Memory required for data: 3207360
I0628 16:43:16.653594 23581 layer_factory.hpp:77] Creating layer conv3/bn
I0628 16:43:16.653609 23581 net.cpp:86] Creating Layer conv3/bn
I0628 16:43:16.653617 23581 net.cpp:408] conv3/bn <- conv3
I0628 16:43:16.653630 23581 net.cpp:369] conv3/bn -> conv3 (in-place)
I0628 16:43:16.653988 23581 net.cpp:124] Setting up conv3/bn
I0628 16:43:16.654006 23581 net.cpp:131] Top shape: 16 48 6 6 (27648)
I0628 16:43:16.654011 23581 net.cpp:139] Memory required for data: 3317952
I0628 16:43:16.654031 23581 layer_factory.hpp:77] Creating layer conv3/scale
I0628 16:43:16.654043 23581 net.cpp:86] Creating Layer conv3/scale
I0628 16:43:16.654050 23581 net.cpp:408] conv3/scale <- conv3
I0628 16:43:16.654068 23581 net.cpp:369] conv3/scale -> conv3 (in-place)
I0628 16:43:16.654148 23581 layer_factory.hpp:77] Creating layer conv3/scale
I0628 16:43:16.654371 23581 net.cpp:124] Setting up conv3/scale
I0628 16:43:16.654387 23581 net.cpp:131] Top shape: 16 48 6 6 (27648)
I0628 16:43:16.654395 23581 net.cpp:139] Memory required for data: 3428544
I0628 16:43:16.654407 23581 layer_factory.hpp:77] Creating layer relu3
I0628 16:43:16.654418 23581 net.cpp:86] Creating Layer relu3
I0628 16:43:16.654424 23581 net.cpp:408] relu3 <- conv3
I0628 16:43:16.654436 23581 net.cpp:369] relu3 -> conv3 (in-place)
I0628 16:43:16.655385 23581 net.cpp:124] Setting up relu3
I0628 16:43:16.655434 23581 net.cpp:131] Top shape: 16 48 6 6 (27648)
I0628 16:43:16.655442 23581 net.cpp:139] Memory required for data: 3539136
I0628 16:43:16.655449 23581 layer_factory.hpp:77] Creating layer ip1
I0628 16:43:16.655463 23581 net.cpp:86] Creating Layer ip1
I0628 16:43:16.655472 23581 net.cpp:408] ip1 <- conv3
I0628 16:43:16.655486 23581 net.cpp:382] ip1 -> ip1
I0628 16:43:16.658191 23581 net.cpp:124] Setting up ip1
I0628 16:43:16.658213 23581 net.cpp:131] Top shape: 16 128 (2048)
I0628 16:43:16.658219 23581 net.cpp:139] Memory required for data: 3547328
I0628 16:43:16.658231 23581 layer_factory.hpp:77] Creating layer ip2
I0628 16:43:16.658244 23581 net.cpp:86] Creating Layer ip2
I0628 16:43:16.658252 23581 net.cpp:408] ip2 <- ip1
I0628 16:43:16.658262 23581 net.cpp:382] ip2 -> ip2
I0628 16:43:16.658468 23581 net.cpp:124] Setting up ip2
I0628 16:43:16.658484 23581 net.cpp:131] Top shape: 16 4 (64)
I0628 16:43:16.658490 23581 net.cpp:139] Memory required for data: 3547584
I0628 16:43:16.658501 23581 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I0628 16:43:16.658514 23581 net.cpp:86] Creating Layer ip2_ip2_0_split
I0628 16:43:16.658521 23581 net.cpp:408] ip2_ip2_0_split <- ip2
I0628 16:43:16.658532 23581 net.cpp:382] ip2_ip2_0_split -> ip2_ip2_0_split_0
I0628 16:43:16.658545 23581 net.cpp:382] ip2_ip2_0_split -> ip2_ip2_0_split_1
I0628 16:43:16.658617 23581 net.cpp:124] Setting up ip2_ip2_0_split
I0628 16:43:16.658632 23581 net.cpp:131] Top shape: 16 4 (64)
I0628 16:43:16.658639 23581 net.cpp:131] Top shape: 16 4 (64)
I0628 16:43:16.658644 23581 net.cpp:139] Memory required for data: 3548096
I0628 16:43:16.658651 23581 layer_factory.hpp:77] Creating layer loss
I0628 16:43:16.658661 23581 net.cpp:86] Creating Layer loss
I0628 16:43:16.658668 23581 net.cpp:408] loss <- ip2_ip2_0_split_0
I0628 16:43:16.658676 23581 net.cpp:408] loss <- label_data_1_split_0
I0628 16:43:16.658689 23581 net.cpp:382] loss -> loss
I0628 16:43:16.658704 23581 layer_factory.hpp:77] Creating layer loss
I0628 16:43:16.660559 23581 net.cpp:124] Setting up loss
I0628 16:43:16.660579 23581 net.cpp:131] Top shape: (1)
I0628 16:43:16.660586 23581 net.cpp:134]     with loss weight 1
I0628 16:43:16.660601 23581 net.cpp:139] Memory required for data: 3548100
I0628 16:43:16.660609 23581 layer_factory.hpp:77] Creating layer acc
I0628 16:43:16.660624 23581 net.cpp:86] Creating Layer acc
I0628 16:43:16.660630 23581 net.cpp:408] acc <- ip2_ip2_0_split_1
I0628 16:43:16.660640 23581 net.cpp:408] acc <- label_data_1_split_1
I0628 16:43:16.660648 23581 net.cpp:382] acc -> acc
I0628 16:43:16.660665 23581 net.cpp:124] Setting up acc
I0628 16:43:16.660673 23581 net.cpp:131] Top shape: (1)
I0628 16:43:16.660679 23581 net.cpp:139] Memory required for data: 3548104
I0628 16:43:16.660686 23581 net.cpp:202] acc does not need backward computation.
I0628 16:43:16.660693 23581 net.cpp:200] loss needs backward computation.
I0628 16:43:16.660701 23581 net.cpp:200] ip2_ip2_0_split needs backward computation.
I0628 16:43:16.660706 23581 net.cpp:200] ip2 needs backward computation.
I0628 16:43:16.660712 23581 net.cpp:200] ip1 needs backward computation.
I0628 16:43:16.660718 23581 net.cpp:200] relu3 needs backward computation.
I0628 16:43:16.660724 23581 net.cpp:200] conv3/scale needs backward computation.
I0628 16:43:16.660730 23581 net.cpp:200] conv3/bn needs backward computation.
I0628 16:43:16.660735 23581 net.cpp:200] conv3 needs backward computation.
I0628 16:43:16.660742 23581 net.cpp:200] relu2 needs backward computation.
I0628 16:43:16.660748 23581 net.cpp:200] conv2/scale needs backward computation.
I0628 16:43:16.660753 23581 net.cpp:200] conv2/bn needs backward computation.
I0628 16:43:16.660758 23581 net.cpp:200] conv2 needs backward computation.
I0628 16:43:16.660763 23581 net.cpp:200] relu1 needs backward computation.
I0628 16:43:16.660769 23581 net.cpp:200] conv1/scale needs backward computation.
I0628 16:43:16.660775 23581 net.cpp:200] conv1/bn needs backward computation.
I0628 16:43:16.660780 23581 net.cpp:200] conv1 needs backward computation.
I0628 16:43:16.660815 23581 net.cpp:202] label_data_1_split does not need backward computation.
I0628 16:43:16.660825 23581 net.cpp:202] data does not need backward computation.
I0628 16:43:16.660830 23581 net.cpp:244] This network produces output acc
I0628 16:43:16.660836 23581 net.cpp:244] This network produces output loss
I0628 16:43:16.660862 23581 net.cpp:257] Network initialization done.
I0628 16:43:16.660989 23581 solver.cpp:57] Solver scaffolding done.
I0628 16:43:16.662999 23581 caffe.cpp:239] Starting Optimization
I0628 16:43:16.663015 23581 solver.cpp:289] Solving simpleconv3
I0628 16:43:16.663022 23581 solver.cpp:290] Learning Rate Policy: fixed
I0628 16:43:16.664417 23581 solver.cpp:347] Iteration 0, Testing net (#0)
I0628 16:43:16.673065 23581 blocking_queue.cpp:49] Waiting for data
I0628 16:43:17.303195 23581 solver.cpp:414]     Test net output #0: acc = 0.226875
I0628 16:43:17.303230 23581 solver.cpp:414]     Test net output #1: loss = 67.5221 (* 1 = 67.5221 loss)
I0628 16:43:17.314468 23581 solver.cpp:239] Iteration 0 (-2.40415e-23 iter/s, 0.651413s/100 iters), loss = 1.45347
I0628 16:43:17.314548 23581 solver.cpp:258]     Train net output #0: acc = 0.229167
I0628 16:43:17.314563 23581 solver.cpp:258]     Train net output #1: loss = 1.45347 (* 1 = 1.45347 loss)
I0628 16:43:17.314574 23581 sgd_solver.cpp:112] Iteration 0, lr = 1e-05
I0628 16:43:20.062227 23581 solver.cpp:347] Iteration 100, Testing net (#0)
I0628 16:43:20.521803 23581 solver.cpp:414]     Test net output #0: acc = 0.4125
I0628 16:43:20.521883 23581 solver.cpp:414]     Test net output #1: loss = 1.1864 (* 1 = 1.1864 loss)
I0628 16:43:20.527089 23581 solver.cpp:239] Iteration 100 (31.1279 iter/s, 3.21256s/100 iters), loss = 1.27631
I0628 16:43:20.527137 23581 solver.cpp:258]     Train net output #0: acc = 0.416667
I0628 16:43:20.527151 23581 solver.cpp:258]     Train net output #1: loss = 1.27631 (* 1 = 1.27631 loss)
I0628 16:43:20.527159 23581 sgd_solver.cpp:112] Iteration 100, lr = 1e-05
I0628 16:43:23.439510 23581 solver.cpp:347] Iteration 200, Testing net (#0)
I0628 16:43:24.059273 23581 solver.cpp:414]     Test net output #0: acc = 0.428125
I0628 16:43:24.059352 23581 solver.cpp:414]     Test net output #1: loss = 1.13453 (* 1 = 1.13453 loss)
I0628 16:43:24.067615 23581 solver.cpp:239] Iteration 200 (28.2447 iter/s, 3.54049s/100 iters), loss = 1.2247
I0628 16:43:24.067673 23581 solver.cpp:258]     Train net output #0: acc = 0.416667
I0628 16:43:24.067698 23581 solver.cpp:258]     Train net output #1: loss = 1.2247 (* 1 = 1.2247 loss)
I0628 16:43:24.067713 23581 sgd_solver.cpp:112] Iteration 200, lr = 1e-05
I0628 16:43:26.985738 23581 solver.cpp:347] Iteration 300, Testing net (#0)
